# RWE LLM Validator

A tool for validating research papers against the RECORD (REporting of studies Conducted using Observational Routinely-collected Data) guidelines using Large Language Models (LLMs).

## Overview

This project uses a combination of OpenAI and Anthropic LLMs to validate research papers against the RECORD guidelines:

1. **Reasoner (OpenAI)**: Extracts guideline items from RECORD PDFs and generates prompts
2. **Extractor (OpenAI)**: Extracts information from research papers based on the prompts
3. **Validator (Claude)**: Validates the extracted information against the guideline items

## Setup

### Prerequisites

- Python 3.8+
- OpenAI API key
- Anthropic API key
- DeepSeek API key (optional)

### Installation

1. Clone the repository:
   ```
   git clone <repository-url>
   cd RWE_LLM_validator
   ```

2. Install the required packages:
   ```
   pip install -r requirements.txt
   ```

3. Create a `.env` file in the root directory with your API keys:
   ```
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   DEEPSEEK_API_KEY=your_deepseek_api_key
   ```

## Running the Code

### Single Paper Validation

The main script for running the validation on a single paper is `test_record_validation_openai_claude_fixed.py`. This script can be run in three different modes:

#### Full Mode (Default)

Runs the complete pipeline: Reasoner → Extractor → Validator

```bash
python test_record_validation_openai_claude_fixed.py
```

To specify a different paper:

```bash
python test_record_validation_openai_claude_fixed.py --paper data/Papers/34999649.pdf
```

#### Reasoner Mode

Only runs the Reasoner part (LLM1) to generate prompts:

```bash
python test_record_validation_openai_claude_fixed.py --mode reasoner
```

#### Extractor Mode

Runs only the Extractor and Validator parts (LLM2 + LLM3) using existing prompts:

```bash
python test_record_validation_openai_claude_fixed.py --mode extractor --prompts path/to/prompts.json
```

### Batch Processing Multiple Papers

To run validation on all papers in the `data/Papers/` directory or a specific paper, use the `run_all_papers.py` script:

```bash
# Process all papers in data/Papers/
python run_all_papers.py

# Process a specific paper
python run_all_papers.py --paper data/Papers/34999649.pdf

# Run in reasoner mode only
python run_all_papers.py --mode reasoner

# Run in extractor mode with existing prompts
python run_all_papers.py --mode extractor --prompts path/to/prompts.json
```

This script will:
1. Process each paper through the validation pipeline
2. Organize results in the `output/paper_results/` directory
3. Generate a summary of all processed papers
4. Run the cleanup script to organize the output directory

## Output Files

The script generates various output files in the `output` directory. After running the cleanup script, the files are organized as follows:

### Latest Run Results (`output/latest_run/`)

- **`*_claude-sonnet_validator_*.json`**: Validation results from Claude
- **`*_full_record_checklist_*.json`**: Final RECORD checklist with correct answers
- **`*_openai-gpt4o_extractor_*.json`**: Extraction results from OpenAI
- **`*_openai_claude_report_*.json`**: Final report combining extraction and validation
- **`*_openai_reasoner_*.json`**: Prompts generated by the Reasoner
- **`*_openai_reasoner_*_process_log.txt`**: Log of the Reasoner process

### Guideline Info (`output/guideline_info/`)

- **`record_guideline_info_*.json`**: Information about the RECORD guidelines

## Cleaning Up

To clean up the output directory and organize the files, run the provided cleanup script:

```bash
./cleanup_output.sh
```

This script:
1. Creates an organized directory structure
2. Moves the latest run results to `output/latest_run/`
3. Moves guideline info files to `output/guideline_info/`
4. Archives older files to `output/archive/`
5. Removes intermediate batch files

## Understanding the Results

### Final Report

The final report (`*_openai_claude_report_*.json`) contains:
- Paper information
- Guideline information
- Validation summary with metrics
- Detailed item-by-item results including:
  - Description of the guideline item
  - Compliance assessment
  - Confidence level
  - Evidence from the paper
  - Correct answer
  - Reasoning

### RECORD Checklist

The RECORD checklist (`*_full_record_checklist_*.json`) contains:
- Paper information
- Guideline information
- Checklist items with:
  - Description of the guideline item
  - Correct answer

## Modifications

The code has been modified to:
1. Replace "paper_title" with "pubmed_id" to reduce token usage
2. Improve the "correct_answer" field to better address the checklist item questions
3. Fix the paper_path attribute to correctly extract the pubmed_id

## Troubleshooting

If you encounter the error `Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.`, the code has been updated to handle this by checking if the model is an o3 model and using the appropriate parameter.
