"""
Extractor Agent (LLM2) for the LLM Validation Framework.

This module contains the Extractor class, which is responsible for:
1. Processing research papers using prompts generated by the Reasoner
2. Extracting information relevant to RECORD guideline items
3. Determining if papers comply with reporting guidelines
4. Using RAG to efficiently retrieve relevant sections of papers
"""

import os
import json
import time
import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import re
from collections import defaultdict

class Extractor:
    """
    LLM2 - The Extractor agent extracts information from research papers.
    
    The Extractor is responsible for:
    1. Processing paper text based on prompts from the Reasoner
    2. Extracting information relevant to each RECORD guideline item
    3. Determining if papers comply with reporting guideline items
    4. Providing evidence for compliance assessments
    5. Using RAG to efficiently retrieve relevant paper sections
    """
    
    def __init__(self, api_keys: Dict[str, str], config: Optional[Dict[str, Any]] = None):
        """
        Initialize the Extractor agent.
        
        Args:
            api_keys: Dictionary containing API keys for LLM providers
            config: Optional configuration parameters
        """
        self.logger = logging.getLogger(__name__)
        self.api_keys = api_keys
        self.config = config or {}
        
        # Store metrics for API calls
        self.call_metrics = {
            "total_calls": 0,
            "total_tokens": 0,
            "total_time_ms": 0
        }
        
        # Initialize vector database for RAG
        self.embeddings = None
        self.document_chunks = []
        self.chunk_embeddings = []
        self.section_map = {}
        self.rag_initialized = False
        
        # Initialize LLM client based on available API keys
        # Prioritize different providers than the Reasoner for better triangulation
        if "anthropic" in api_keys and api_keys["anthropic"]:
            self._initialize_anthropic()
        elif "openai" in api_keys and api_keys["openai"]:
            self._initialize_openai()
        else:
            raise ValueError("No valid API keys provided for Extractor LLM")
            
        # Initialize embeddings model for RAG
        self._initialize_embeddings()
        
    def _initialize_openai(self):
        """Initialize OpenAI client."""
        try:
            from openai import OpenAI
            
            self.client_type = "openai"
            self.client = OpenAI(api_key=self.api_keys["openai"])
            
            # Use model from config or default to gpt-4 (can be gpt-3.5-turbo for cost savings)
            self.model = self.config.get("openai_model", "gpt-4")
            self.logger.info(f"Initialized OpenAI client for Extractor using model: {self.model}")
        except ImportError:
            self.logger.error("Failed to import OpenAI module")
            raise
        except Exception as e:
            self.logger.error(f"Error initializing OpenAI client: {e}")
            raise
    
    def _initialize_anthropic(self):
        """Initialize Anthropic client."""
        try:
            from anthropic import Anthropic
            
            self.client_type = "anthropic"
            self.client = Anthropic(api_key=self.api_keys["anthropic"])
            
            # Use model from config or default to Claude model
            self.model = self.config.get("anthropic_model", "claude-3-sonnet-20240229")
            self.logger.info(f"Initialized Anthropic client for Extractor using model: {self.model}")
        except ImportError:
            self.logger.error("Failed to import Anthropic module")
            raise
        except Exception as e:
            self.logger.error(f"Error initializing Anthropic client: {e}")
            raise
            
    def _initialize_embeddings(self):
        """Initialize embeddings model for RAG."""
        try:
            if "openai" in self.api_keys and self.api_keys["openai"]:
                from openai import OpenAI
                
                self.embeddings_client = OpenAI(api_key=self.api_keys["openai"])
                self.embeddings_model = "text-embedding-3-small"
                self.logger.info(f"Initialized OpenAI embeddings model: {self.embeddings_model}")
            else:
                # Fallback to a local embeddings model if no OpenAI key
                try:
                    from sentence_transformers import SentenceTransformer
                    self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')
                    self.logger.info("Initialized local SentenceTransformer model for embeddings")
                except ImportError:
                    self.logger.warning("SentenceTransformer not available. RAG functionality will be limited.")
                    self.embeddings_model = None
        except Exception as e:
            self.logger.error(f"Error initializing embeddings model: {e}")
            self.embeddings_model = None
    
    def extract_information(self, paper_text: str, prompt: str, item_id: str) -> Dict[str, Any]:
        """
        Extract information from paper text based on a prompt.
        
        Args:
            paper_text: Text extracted from a research paper
            prompt: Prompt generated by the Reasoner for a specific guideline item
            item_id: ID of the guideline item being checked
            
        Returns:
            Dictionary containing extracted information and compliance assessment
        """
        self.logger.info(f"Extracting information for guideline item: {item_id}")
        
        # For simpler implementation, we'll use a basic chunking approach
        # In a production system, you would use the RAG implementation
        
        # Chunk the paper text
        chunks = self._chunk_text(paper_text)
        chunk_count = len(chunks)
        
        self.logger.info(f"Paper text split into {chunk_count} chunks")
        
        # Initialize extraction results
        extraction = {
            "item_id": item_id,
            "compliance": "unknown",
            "evidence": [],
            "confidence": 0.0,
            "reasoning": ""
        }
        
        # Process each chunk and combine results
        for i, chunk in enumerate(chunks):
            self.logger.info(f"Processing chunk {i+1}/{chunk_count} for item {item_id}")
            
            # Include chunk info in prompt for context
            chunk_prompt = f"""
            {prompt}
            
            PAPER TEXT (PART {i+1}/{chunk_count}):
            {chunk}
            
            Please provide your extraction in the following JSON format:
            {{
                "compliance": "yes", "partial", "no", or "unknown",
                "evidence": [
                    {{
                        "quote": "direct quote from paper",
                        "location": "section/page information if available"
                    }}
                ],
                "confidence": 0.0-1.0 (your confidence in this assessment),
                "reasoning": "explanation of your assessment"
            }}
            
            Focus only on this specific guideline item. If you can't find relevant information in 
            this chunk, indicate that with "unknown" compliance and explain in the reasoning.
            """
            
            # Call LLM to extract information from this chunk
            result = self._call_llm(chunk_prompt)
            
            # Parse the result
            chunk_extraction = self._parse_extraction_result(result)
            
            # Combine with previous chunks' results
            extraction = self._combine_chunk_extractions(extraction, chunk_extraction, i)
        
        # Finalize the extraction
        return self._finalize_extraction(extraction, item_id)
        
    def _chunk_text(self, text: str) -> List[str]:
        """
        Split text into manageable chunks for processing.
        
        Args:
            text: Text to be chunked
            
        Returns:
            List of text chunks
        """
        # Define max tokens per chunk (approximation)
        max_tokens = self.config.get("chunk_size", 8000)
        
        # If text is short enough, return as a single chunk
        if len(text) / 4 < max_tokens:  # Rough approximation: 1 token â‰ˆ 4 chars
            return [text]
        
        # Otherwise, split into chunks
        chunks = []
        paragraphs = re.split(r'\n\s*\n', text)
        
        current_chunk = ""
        current_length = 0
        
        for paragraph in paragraphs:
            para_length = len(paragraph) / 4  # Approximate token count
            
            # If adding this paragraph would exceed the limit, start a new chunk
            if current_length + para_length > max_tokens and current_chunk:
                chunks.append(current_chunk)
                current_chunk = paragraph
                current_length = para_length
            else:
                # Otherwise, add to current chunk
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
                current_length += para_length
        
        # Add the last chunk if not empty
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
        
    def _call_llm(self, prompt: str) -> str:
        """
        Call LLM with appropriate parameters based on client type.
        
        Args:
            prompt: Prompt to send to LLM
            
        Returns:
            Response from LLM
        """
        start_time = time.time()
        result = ""
        
        try:
            if self.client_type == "openai":
                # Call OpenAI API
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2,
                    max_tokens=2000
                )
                
                result = response.choices[0].message.content
                
                # Update metrics
                prompt_tokens = response.usage.prompt_tokens
                completion_tokens = response.usage.completion_tokens
                
            elif self.client_type == "anthropic":
                # Call Anthropic API
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.2,
                    messages=[{"role": "user", "content": prompt}]
                )
                
                result = response.content[0].text
                
                # Approximate token counts for Anthropic
                prompt_tokens = len(prompt) // 4  # Rough approximation
                completion_tokens = len(result) // 4  # Rough approximation
            
            # Calculate time taken
            time_taken_ms = (time.time() - start_time) * 1000
            
            # Update call metrics
            self.call_metrics["total_calls"] += 1
            self.call_metrics["total_tokens"] += (prompt_tokens + completion_tokens)
            self.call_metrics["total_time_ms"] += time_taken_ms
            
            self.logger.info(f"LLM call completed in {time_taken_ms:.2f}ms, "
                           f"used {prompt_tokens} prompt tokens and {completion_tokens} completion tokens")
            
            return result
        
        except Exception as e:
            self.logger.error(f"Error calling LLM: {e}")
            return "{}"
            
    def _parse_extraction_result(self, result: str) -> Dict[str, Any]:
        """
        Parse the result from the LLM extraction.
        
        Args:
            result: LLM response text
            
        Returns:
            Parsed extraction as a dictionary
        """
        try:
            # Try to parse the entire response as JSON
            extraction = json.loads(result)
            return extraction
        except json.JSONDecodeError:
            # Try to extract JSON from text
            json_match = re.search(r'(\{.*\})', result, re.DOTALL)
            if json_match:
                try:
                    extracted_json = json_match.group(1)
                    extraction = json.loads(extracted_json)
                    return extraction
                except json.JSONDecodeError:
                    pass
            
            # If all else fails, create a basic extraction
            self.logger.warning("Failed to parse extraction result as JSON")
            return {
                "compliance": "unknown",
                "evidence": [],
                "confidence": 0.0,
                "reasoning": f"Failed to parse result: {result[:500]}..."  # Include part of the result
            }
    
    def _combine_chunk_extractions(self, current: Dict[str, Any], 
                                 chunk: Dict[str, Any], 
                                 chunk_index: int) -> Dict[str, Any]:
        """
        Combine extraction results from multiple chunks.
        
        Args:
            current: Current combined extraction
            chunk: Extraction from current chunk
            chunk_index: Index of the current chunk
            
        Returns:
            Updated combined extraction
        """
        # For the first chunk, initialize with its values
        if chunk_index == 0:
            return chunk
            
        # Combine evidence
        evidence = current.get("evidence", [])
        new_evidence = chunk.get("evidence", [])
        
        # Add only new evidence (avoid duplicates)
        for item in new_evidence:
            if item and item.get("quote") and not any(
                existing.get("quote") == item.get("quote") for existing in evidence
            ):
                evidence.append(item)
        
        # Update compliance based on confidence and evidence
        current_compliance = current.get("compliance", "unknown")
        current_confidence = current.get("confidence", 0.0)
        chunk_compliance = chunk.get("compliance", "unknown")
        chunk_confidence = chunk.get("confidence", 0.0)
        
        # Compliance precedence: yes < partial < no < unknown
        compliance_rank = {"yes": 1, "partial": 2, "no": 3, "unknown": 4}
        
        # If the new chunk has higher confidence for a concrete assessment, update compliance
        if (chunk_compliance != "unknown" and 
            (current_compliance == "unknown" or chunk_confidence > current_confidence)):
            compliance = chunk_compliance
        # If the new chunk has same confidence but higher precedence, update compliance
        elif (chunk_confidence >= current_confidence and 
              compliance_rank.get(chunk_compliance, 4) > compliance_rank.get(current_compliance, 4)):
            compliance = chunk_compliance
        else:
            compliance = current_compliance
        
        # Update confidence (weighted average based on chunk index)
        total_weight = sum(range(1, chunk_index + 2))  # Sum 1 to current chunk index + 1
        weighted_confidence = (
            current_confidence * sum(range(1, chunk_index + 1)) / total_weight +
            chunk_confidence * (chunk_index + 1) / total_weight
        )
        
        # Combine reasoning
        reasoning = current.get("reasoning", "") + "\n\n" + chunk.get("reasoning", "")
        
        return {
            "item_id": current.get("item_id", ""),
            "compliance": compliance,
            "evidence": evidence,
            "confidence": weighted_confidence,
            "reasoning": reasoning
        }
        
    def _finalize_extraction(self, extraction: Dict[str, Any], item_id: str) -> Dict[str, Any]:
        """
        Finalize the extraction results.
        
        Args:
            extraction: Combined extraction from all chunks
            item_id: ID of the guideline item
            
        Returns:
            Finalized extraction
        """
        # Ensure item_id is set
        extraction["item_id"] = item_id
        
        # Deduplicate evidence
        if "evidence" in extraction:
            seen = set()
            deduped_evidence = []
            
            for ev in extraction["evidence"]:
                # Skip empty evidence
                if not ev or "quote" not in ev:
                    continue
                    
                # Create a hashable representation
                quote = ev.get("quote", "").strip()
                if not quote:
                    continue
                    
                quote_hash = hash(quote)
                if quote_hash not in seen:
                    seen.add(quote_hash)
                    deduped_evidence.append(ev)
            
            extraction["evidence"] = deduped_evidence
        
        # Set a default confidence if missing
        if "confidence" not in extraction or extraction["confidence"] is None:
            extraction["confidence"] = 0.0
        
        # Summarize the reasoning if it's too long
        if "reasoning" in extraction and len(extraction["reasoning"]) > 1000:
            extraction["reasoning"] = extraction["reasoning"][:500] + "...\n\n[Reasoning truncated]"
        
        return extraction